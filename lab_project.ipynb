{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-09T06:49:53.074410Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import threading\n",
    "import logging\n",
    "from collections import deque\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ImageProcessor:\n",
    "    def __init__(self):\n",
    "        self.face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        self.prev_gray = None\n",
    "        self.prev_transform = None\n",
    "        self.transform_differences = deque(maxlen=10)\n",
    "        self.target_size = (640, 480)\n",
    "        self.prev_frames = deque(maxlen=5)\n",
    "        self.key_points = None\n",
    "        self.its_values = []  # Add list to store ITS values\n",
    "    \n",
    "    def resize_frame(self, frame: np.ndarray) -> np.ndarray:\n",
    "        if frame is None or frame.size == 0:\n",
    "            logger.warning(\"Empty frame received in resize_frame\")\n",
    "            return frame\n",
    "            \n",
    "        try:\n",
    "            return cv2.resize(frame, self.target_size)\n",
    "        except cv2.error as e:\n",
    "            logger.error(f\"Error resizing frame: {e}\")\n",
    "            return frame\n",
    "            \n",
    "    def adjust_image(self, frame: np.ndarray, gamma: float, brightness: float, contrast: float) -> np.ndarray:\n",
    "        if frame is None or frame.size == 0:\n",
    "            logger.warning(\"Empty frame received in adjust_image\")\n",
    "            return frame\n",
    "            \n",
    "        try:\n",
    "            inv_gamma = 1.0 / gamma\n",
    "            table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "            frame = cv2.LUT(frame, table)\n",
    "            return cv2.convertScaleAbs(frame, alpha=contrast, beta=brightness)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error adjusting image: {e}\")\n",
    "            return frame\n",
    "            \n",
    "    def detect_and_process_faces(self, frame: np.ndarray, detect: bool, blur: bool) -> np.ndarray:\n",
    "        if frame is None or frame.size == 0:\n",
    "            logger.warning(\"Empty frame received in detect_and_process_faces\")\n",
    "            return frame\n",
    "\n",
    "        try:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = self.face_detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                # Add boundary checks\n",
    "                x = max(0, x)\n",
    "                y = max(0, y)\n",
    "                w = min(w, frame.shape[1] - x)\n",
    "                h = min(h, frame.shape[0] - y)\n",
    "\n",
    "                if blur and w > 0 and h > 0:  # Only blur if region is valid\n",
    "                    try:\n",
    "                        face_region = frame[y:y + h, x:x + w]\n",
    "                        if face_region.size > 0:  # Check if region is not empty\n",
    "                            blurred_region = cv2.GaussianBlur(face_region, (99, 99), 30)\n",
    "                            frame[y:y + h, x:x + w] = blurred_region\n",
    "                    except cv2.error as e:\n",
    "                        logger.error(f\"Error applying blur to face region: {e}\")\n",
    "                        continue\n",
    "\n",
    "                if detect:\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            return frame\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in detect_and_process_faces: {e}\")\n",
    "            return frame\n",
    "            \n",
    "    def optical_flow_stabilization(self, frame: np.ndarray) -> tuple[np.ndarray, float]:\n",
    "        frame = self.resize_frame(frame)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if self.prev_gray is None:\n",
    "            self.prev_gray = gray\n",
    "            return frame, 0.0\n",
    "\n",
    "        try:\n",
    "            flow = cv2.calcOpticalFlowFarneback(self.prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "            dx, dy = np.mean(flow[..., 0]), np.mean(flow[..., 1])\n",
    "            transform = np.array([[1, 0, -dx], [0, 1, -dy], [0, 0, 1]])\n",
    "            height, width = frame.shape[:2]\n",
    "            stabilized_frame = cv2.warpAffine(frame, transform[:2], (width, height))\n",
    "            its_value = self.update_its(transform)\n",
    "            self.prev_gray = gray\n",
    "            self.prev_transform = transform\n",
    "            return stabilized_frame, its_value\n",
    "        except cv2.error as e:\n",
    "            logger.error(f\"Error in optical flow calculation: {e}\")\n",
    "            self.prev_gray = gray\n",
    "            return frame, 0.0\n",
    "\n",
    "    def moving_average_stabilization(self, frame: np.ndarray) -> tuple[np.ndarray, float]:\n",
    "        self.prev_frames.append(frame)\n",
    "        if len(self.prev_frames) < 2:\n",
    "            return frame, 0.0\n",
    "        \n",
    "        stabilized = np.mean(self.prev_frames, axis=0).astype(np.uint8)\n",
    "        its_value = np.mean([np.sum(np.abs(stabilized - f)) for f in self.prev_frames]) / (frame.shape[0] * frame.shape[1])\n",
    "        return stabilized, its_value\n",
    "\n",
    "    def feature_based_stabilization(self, frame: np.ndarray) -> tuple[np.ndarray, float]:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Initialize ORB detector\n",
    "        orb = cv2.ORB_create()\n",
    "        \n",
    "        if self.key_points is None:\n",
    "            self.key_points = gray\n",
    "            return frame, 0.0\n",
    "            \n",
    "        try:\n",
    "            # Find keypoints and descriptors\n",
    "            kp1, des1 = orb.detectAndCompute(self.key_points, None)\n",
    "            kp2, des2 = orb.detectAndCompute(gray, None)\n",
    "            \n",
    "            if des1 is None or des2 is None or len(kp1) < 2 or len(kp2) < 2:\n",
    "                self.key_points = gray\n",
    "                return frame, 0.0\n",
    "            \n",
    "            # Create matcher and match features\n",
    "            bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "            matches = bf.match(des1, des2)\n",
    "            \n",
    "            # Sort matches by distance\n",
    "            matches = sorted(matches, key=lambda x: x.distance)\n",
    "            \n",
    "            # Get matched keypoints\n",
    "            src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "            dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "            \n",
    "            # Calculate transformation matrix\n",
    "            M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "            \n",
    "            if M is not None:\n",
    "                # Apply transformation\n",
    "                h, w = frame.shape[:2]\n",
    "                stabilized_frame = cv2.warpPerspective(frame, M, (w, h))\n",
    "                its_value = np.sum(np.abs(M - np.eye(3))) / 9  # Measure of transformation magnitude\n",
    "                self.key_points = gray\n",
    "                return stabilized_frame, its_value\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in feature-based stabilization: {e}\")\n",
    "        \n",
    "        self.key_points = gray\n",
    "        return frame, 0.0\n",
    "\n",
    "    def update_its(self, transform: np.ndarray) -> float:\n",
    "        if self.prev_transform is not None:\n",
    "            diff = np.linalg.norm(transform - self.prev_transform)\n",
    "            self.transform_differences.append(diff)\n",
    "            return np.mean(self.transform_differences)\n",
    "        return 0.0\n",
    "\n",
    "    def reset_stabilization(self):\n",
    "        self.prev_gray = None\n",
    "        self.prev_transform = None\n",
    "        self.transform_differences.clear()\n",
    "        self.prev_frames.clear()\n",
    "        self.key_points = None\n",
    "        self.its_values.clear()  # Clear ITS values on reset\n",
    "    def get_average_its(self):\n",
    "        return np.mean(self.its_values) if self.its_values else 0.0\n",
    "\n",
    "\n",
    "class VideoProcessingDialog:\n",
    "    def __init__(self, parent):\n",
    "        self.dialog = tk.Toplevel(parent)\n",
    "        self.dialog.title(\"Video Processing Options\")\n",
    "        self.dialog.geometry(\"400x500\")\n",
    "        self.dialog.transient(parent)\n",
    "        self.dialog.grab_set()  # Make dialog modal\n",
    "        \n",
    "        # Processing options\n",
    "        self.face_detection = tk.BooleanVar(value=False)\n",
    "        self.face_blur = tk.BooleanVar(value=False)\n",
    "        self.auto_adjust = tk.BooleanVar(value=False)\n",
    "        self.stabilization = tk.StringVar(value=\"Off\")\n",
    "        self.save_output = tk.BooleanVar(value=False)\n",
    "        self.output_path = None\n",
    "        \n",
    "        self.setup_ui()\n",
    "        self.result = None\n",
    "\n",
    "    def setup_ui(self):\n",
    "        # Main frame\n",
    "        main_frame = ttk.Frame(self.dialog, padding=\"20\")\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Title\n",
    "        title_label = ttk.Label(main_frame, text=\"Select Processing Features\", \n",
    "                               font=('Helvetica', 12, 'bold'))\n",
    "        title_label.pack(pady=(0, 20))\n",
    "        \n",
    "        # Processing options frame\n",
    "        options_frame = ttk.LabelFrame(main_frame, text=\"Processing Options\", padding=\"10\")\n",
    "        options_frame.pack(fill=tk.X, pady=(0, 20))\n",
    "        \n",
    "        ttk.Checkbutton(options_frame, text=\"Face Detection\", \n",
    "                       variable=self.face_detection).pack(anchor=\"w\", pady=5)\n",
    "        ttk.Checkbutton(options_frame, text=\"Face Blur\", \n",
    "                       variable=self.face_blur).pack(anchor=\"w\", pady=5)\n",
    "        ttk.Checkbutton(options_frame, text=\"Auto Adjust Lighting\", \n",
    "                       variable=self.auto_adjust).pack(anchor=\"w\", pady=5)\n",
    "        \n",
    "        # Stabilization options\n",
    "        ttk.Label(options_frame, text=\"Stabilization Method:\").pack(anchor=\"w\", pady=(10, 5))\n",
    "        methods = [\"Off\", \"Optical Flow\", \"Moving Average\", \"Feature Based\"]\n",
    "        for method in methods:\n",
    "            ttk.Radiobutton(options_frame, text=method, value=method, \n",
    "                           variable=self.stabilization).pack(anchor=\"w\", padx=20, pady=2)\n",
    "        \n",
    "        # Save options\n",
    "        save_frame = ttk.LabelFrame(main_frame, text=\"Save Options\", padding=\"10\")\n",
    "        save_frame.pack(fill=tk.X, pady=(0, 20))\n",
    "        \n",
    "        ttk.Checkbutton(save_frame, text=\"Save Processed Video\", \n",
    "                       variable=self.save_output, \n",
    "                       command=self.toggle_save_options).pack(anchor=\"w\", pady=5)\n",
    "        \n",
    "        self.save_button = ttk.Button(save_frame, text=\"Select Save Location\", \n",
    "                                    command=self.select_save_location, state='disabled')\n",
    "        self.save_button.pack(anchor=\"w\", pady=5)\n",
    "        \n",
    "        self.save_path_label = ttk.Label(save_frame, text=\"No save location selected\", \n",
    "                                       wraplength=350)\n",
    "        self.save_path_label.pack(anchor=\"w\", pady=5)\n",
    "        \n",
    "        # Buttons frame\n",
    "        buttons_frame = ttk.Frame(main_frame)\n",
    "        buttons_frame.pack(fill=tk.X, pady=(20, 0))\n",
    "        \n",
    "        ttk.Button(buttons_frame, text=\"Cancel\", \n",
    "                  command=self.cancel).pack(side=tk.RIGHT, padx=5)\n",
    "        ttk.Button(buttons_frame, text=\"Process\", \n",
    "                  command=self.process).pack(side=tk.RIGHT, padx=5)\n",
    "\n",
    "    def toggle_save_options(self):\n",
    "        if self.save_output.get():\n",
    "            self.save_button.configure(state='normal')\n",
    "        else:\n",
    "            self.save_button.configure(state='disabled')\n",
    "            self.output_path = None\n",
    "            self.save_path_label.configure(text=\"No save location selected\")\n",
    "\n",
    "    def select_save_location(self):\n",
    "        path = filedialog.asksaveasfilename(\n",
    "            defaultextension=\".mp4\",\n",
    "            filetypes=[(\"MP4 files\", \"*.mp4\"), (\"All files\", \"*.*\")]\n",
    "        )\n",
    "        if path:\n",
    "            self.output_path = path\n",
    "            self.save_path_label.configure(text=f\"Save location: {path}\")\n",
    "\n",
    "    def cancel(self):\n",
    "        self.result = None\n",
    "        self.dialog.destroy()\n",
    "\n",
    "    def process(self):\n",
    "        if self.save_output.get() and not self.output_path:\n",
    "            messagebox.showerror(\"Error\", \"Please select a save location first!\")\n",
    "            return\n",
    "            \n",
    "        self.result = {\n",
    "            'face_detection': self.face_detection.get(),\n",
    "            'face_blur': self.face_blur.get(),\n",
    "            'auto_adjust': self.auto_adjust.get(),\n",
    "            'stabilization': self.stabilization.get(),\n",
    "            'save_output': self.save_output.get(),\n",
    "            'output_path': self.output_path\n",
    "        }\n",
    "        self.dialog.destroy()\n",
    "\n",
    "\n",
    "class CameraApp:\n",
    "    def __init__(self):\n",
    "        self.window = tk.Tk()\n",
    "        self.window.title(\"Video Processing App\")\n",
    "        self.window.geometry(\"1200x700\")\n",
    "\n",
    "        # Initialize video-related variables first\n",
    "        self.video_cap = None\n",
    "        self.stabilization_method = \"Off\"\n",
    "        self.stop_video_thread = threading.Event()\n",
    "        self.video_thread = None\n",
    "        self.lock = threading.Lock()\n",
    "        self.is_video_loaded = False\n",
    "        self.processing_video = False\n",
    "\n",
    "        # Then initialize the rest\n",
    "        self.image_processor = ImageProcessor()\n",
    "        self.setup_variables()\n",
    "        self.setup_ui()\n",
    "        self.setup_camera()\n",
    "        \n",
    "    def update_display(self, frame, its_value):\n",
    "        \"\"\"Update the UI with the current frame\"\"\"\n",
    "        try:\n",
    "            if frame is None or frame.size == 0:\n",
    "                logger.warning(\"Empty frame received in update_display\")\n",
    "                return\n",
    "\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(image)\n",
    "            image = ImageTk.PhotoImage(image)\n",
    "            self.video_label.config(image=image)\n",
    "            self.video_label.image = image\n",
    "            self.its_label.config(text=f\"ITS: {its_value:.2f}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error updating display: {e}\")\n",
    "            \n",
    "    def run(self):\n",
    "        \"\"\"Start the application main loop\"\"\"\n",
    "        try:\n",
    "            # Set up the window close handler\n",
    "            self.window.protocol(\"WM_DELETE_WINDOW\", self.close)\n",
    "            # Start the main event loop\n",
    "            self.window.mainloop()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in main loop: {e}\")\n",
    "        finally:\n",
    "            # Ensure cleanup happens\n",
    "            self.close()\n",
    "    def setup_variables(self):\n",
    "        self.face_detection_on = tk.BooleanVar(value=True)\n",
    "        self.blur_on = tk.BooleanVar(value=False)\n",
    "        self.auto_adjust_on = tk.BooleanVar(value=True)\n",
    "        self.gamma_value = tk.DoubleVar(value=1.0)\n",
    "        self.brightness = tk.DoubleVar(value=0)\n",
    "        self.contrast = tk.DoubleVar(value=1.0)\n",
    "\n",
    "    def setup_ui(self):\n",
    "        main_frame = ttk.Frame(self.window, padding=\"10\")\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "        self.video_label = ttk.Label(main_frame)\n",
    "        self.video_label.pack(pady=5)\n",
    "        self.its_label = ttk.Label(main_frame, text=\"ITS: 0.0\")\n",
    "        self.its_label.pack(pady=2)\n",
    "        controls_frame = ttk.LabelFrame(main_frame, text=\"Controls\", padding=\"5\")\n",
    "        controls_frame.pack(fill=tk.X, pady=5)\n",
    "        ttk.Checkbutton(controls_frame, text=\"Face Detection\", variable=self.face_detection_on).pack(side=tk.LEFT, padx=5)\n",
    "        ttk.Checkbutton(controls_frame, text=\"Face Blur\", variable=self.blur_on).pack(side=tk.LEFT, padx=5)\n",
    "        ttk.Checkbutton(controls_frame, text=\"Auto Adjust\", variable=self.auto_adjust_on).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.stabilization_var = tk.StringVar(value=\"Off\")\n",
    "        stabilization_menu = ttk.OptionMenu(controls_frame, self.stabilization_var, \"Off\", \n",
    "                                          \"Off\", \"Optical Flow\", \"Moving Average\", \"Feature Based\",\n",
    "                                          command=self.change_stabilization_method)\n",
    "        stabilization_menu.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.load_video_btn = ttk.Button(controls_frame, text=\"Load Video\", command=self.load_video)\n",
    "        self.load_video_btn.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        sliders_frame = ttk.LabelFrame(main_frame, text=\"Image Adjustments\", padding=\"5\")\n",
    "        sliders_frame.pack(fill=tk.X, pady=5)\n",
    "        self.create_slider(sliders_frame, \"Gamma\", self.gamma_value, 0.5, 2.0, 0.1)\n",
    "        self.create_slider(sliders_frame, \"Brightness\", self.brightness, -100, 100, 1)\n",
    "        self.create_slider(sliders_frame, \"Contrast\", self.contrast, 0.5, 2.0, 0.1)\n",
    "\n",
    "    def create_slider(self, parent, label, variable, min_val, max_val, resolution):\n",
    "        frame = ttk.Frame(parent)\n",
    "        frame.pack(fill=tk.X, pady=2)\n",
    "        ttk.Label(frame, text=label).pack(side=tk.LEFT, padx=5)\n",
    "        ttk.Scale(frame, from_=min_val, to=max_val, variable=variable, orient=tk.HORIZONTAL).pack(side=tk.LEFT, fill=tk.X, expand=True, padx=5)\n",
    "\n",
    "    def change_stabilization_method(self, method):\n",
    "        self.stabilization_method = method\n",
    "        self.image_processor.reset_stabilization()\n",
    "\n",
    "    def setup_camera(self):\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        if not self.cap.isOpened():\n",
    "            logger.error(\"Failed to open webcam\")\n",
    "            messagebox.showerror(\"Error\", \"Could not open webcam\")\n",
    "            return\n",
    "        self.start_video_thread()\n",
    "\n",
    "\n",
    "    def load_video(self):\n",
    "        video_path = filedialog.askopenfilename(\n",
    "            title=\"Select Video File\",\n",
    "            filetypes=[(\"MP4 files\", \"*.mp4\"), (\"All files\", \"*.*\")]\n",
    "        )\n",
    "        \n",
    "        if video_path:\n",
    "            # Show processing options dialog\n",
    "            dialog = VideoProcessingDialog(self.window)\n",
    "            self.window.wait_window(dialog.dialog)\n",
    "            \n",
    "            if dialog.result is None:  # User cancelled\n",
    "                return\n",
    "                \n",
    "            # Apply selected settings\n",
    "            self.face_detection_on.set(dialog.result['face_detection'])\n",
    "            self.blur_on.set(dialog.result['face_blur'])\n",
    "            self.auto_adjust_on.set(dialog.result['auto_adjust'])\n",
    "            self.stabilization_var.set(dialog.result['stabilization'])\n",
    "            \n",
    "            # Open video\n",
    "            if self.video_cap is not None:\n",
    "                self.video_cap.release()\n",
    "            \n",
    "            self.video_cap = cv2.VideoCapture(video_path)\n",
    "            if not self.video_cap.isOpened():\n",
    "                logger.error(\"Failed to open video\")\n",
    "                messagebox.showerror(\"Error\", \"Failed to open video file\")\n",
    "                self.video_cap = None\n",
    "                return\n",
    "                \n",
    "            self.image_processor.reset_stabilization()\n",
    "            self.is_video_loaded = True\n",
    "            \n",
    "            # If save is enabled, set up video writer\n",
    "            if dialog.result['save_output']:\n",
    "                self.setup_video_writer(dialog.result['output_path'])\n",
    "                threading.Thread(target=self.process_and_save_video, \n",
    "                               args=(video_path, dialog.result)).start()\n",
    "\n",
    "    def setup_video_writer(self, output_path):\n",
    "        fps = self.video_cap.get(cv2.CAP_PROP_FPS)\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        self.video_writer = cv2.VideoWriter(\n",
    "            output_path, \n",
    "            fourcc, \n",
    "            fps, \n",
    "            self.image_processor.target_size\n",
    "        )\n",
    "\n",
    "    def process_and_save_video(self, video_path, settings):\n",
    "        try:\n",
    "            self.processing_video = True\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            processed_frames = 0\n",
    "            \n",
    "            self.stabilization_method = settings['stabilization']\n",
    "            \n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                    \n",
    "                processed_frame, its_value = self.process_frame(frame)\n",
    "                \n",
    "                # Add ITS value display to the frame\n",
    "                h, w = processed_frame.shape[:2]\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.6\n",
    "                thickness = 2\n",
    "                \n",
    "                # Display instantaneous ITS (bottom left)\n",
    "                inst_its_text = f\"ITS: {its_value:.2f}\"\n",
    "                cv2.putText(processed_frame, inst_its_text, (10, h-10), \n",
    "                           font, font_scale, (255, 255, 255), thickness)\n",
    "                \n",
    "                # Calculate and display average ITS (bottom right)\n",
    "                avg_its = self.image_processor.get_average_its()\n",
    "                avg_its_text = f\"Avg ITS: {avg_its:.2f}\"\n",
    "                text_size = cv2.getTextSize(avg_its_text, font, font_scale, thickness)[0]\n",
    "                cv2.putText(processed_frame, avg_its_text, \n",
    "                           (w - text_size[0] - 10, h-10), \n",
    "                           font, font_scale, (255, 255, 255), thickness)\n",
    "                \n",
    "                self.video_writer.write(processed_frame)\n",
    "                \n",
    "                processed_frames += 1\n",
    "                progress = (processed_frames / total_frames) * 100\n",
    "                \n",
    "                if processed_frames % 30 == 0:\n",
    "                    logger.info(f\"Processing progress: {progress:.1f}%\")\n",
    "            \n",
    "            cap.release()\n",
    "            self.video_writer.release()\n",
    "            \n",
    "            # Reset everything\n",
    "            self.is_video_loaded = False\n",
    "            self.video_cap = None\n",
    "            self.stabilization_method = \"Off\"\n",
    "            self.stabilization_var.set(\"Off\")\n",
    "            self.image_processor.reset_stabilization()\n",
    "            \n",
    "            messagebox.showinfo(\"Success\", \"Video processing completed! Saved processed video.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing video: {e}\")\n",
    "            messagebox.showerror(\"Error\", f\"Failed to process video: {str(e)}\")\n",
    "        finally:\n",
    "            if hasattr(self, 'video_writer'):\n",
    "                self.video_writer.release()\n",
    "            self.processing_video = False\n",
    "\n",
    "    \n",
    "    def process_frame(self, frame: np.ndarray) -> tuple[np.ndarray, float]:\n",
    "        if frame is None or frame.size == 0:\n",
    "            logger.warning(\"Empty frame received in process_frame\")\n",
    "            return frame, 0.0\n",
    "\n",
    "        try:\n",
    "            frame = self.image_processor.resize_frame(frame)\n",
    "            if frame is None or frame.size == 0:\n",
    "                return frame, 0.0\n",
    "\n",
    "            if self.auto_adjust_on.get():\n",
    "                try:\n",
    "                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                    mean_brightness = np.mean(gray)\n",
    "                    if mean_brightness < 80:\n",
    "                        self.gamma_value.set(1.5)\n",
    "                        self.brightness.set(50)\n",
    "                        self.contrast.set(1.5)\n",
    "                    elif mean_brightness > 180:\n",
    "                        self.gamma_value.set(0.7)\n",
    "                        self.brightness.set(0)\n",
    "                        self.contrast.set(1.0)\n",
    "                    else:\n",
    "                        self.gamma_value.set(1.0)\n",
    "                        self.brightness.set(0)\n",
    "                        self.contrast.set(1.0)\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error in auto adjustment: {e}\")\n",
    "\n",
    "            frame = self.image_processor.adjust_image(frame, self.gamma_value.get(), \n",
    "                                                    self.brightness.get(), self.contrast.get())\n",
    "            if frame is None or frame.size == 0:\n",
    "                return frame, 0.0\n",
    "\n",
    "            its_value = 0.0\n",
    "            if self.stabilization_method == \"Optical Flow\":\n",
    "                frame, its_value = self.image_processor.optical_flow_stabilization(frame)\n",
    "            elif self.stabilization_method == \"Moving Average\":\n",
    "                frame, its_value = self.image_processor.moving_average_stabilization(frame)\n",
    "            elif self.stabilization_method == \"Feature Based\":\n",
    "                frame, its_value = self.image_processor.feature_based_stabilization(frame)\n",
    "\n",
    "            # Store ITS value for averaging\n",
    "            if its_value > 0:\n",
    "                self.image_processor.its_values.append(its_value)\n",
    "\n",
    "            if frame is None or frame.size == 0:\n",
    "                return frame, 0.0\n",
    "\n",
    "            if self.face_detection_on.get() or self.blur_on.get():\n",
    "                frame = self.image_processor.detect_and_process_faces(frame, \n",
    "                                                                   self.face_detection_on.get(), \n",
    "                                                                   self.blur_on.get())\n",
    "\n",
    "            return frame, its_value\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in process_frame: {e}\")\n",
    "            return frame, 0.0\n",
    "    \n",
    "    def update_video(self):\n",
    "        while not self.stop_video_thread.is_set():\n",
    "            with self.lock:\n",
    "                if self.processing_video:\n",
    "                    continue\n",
    "                    \n",
    "                if self.is_video_loaded and self.video_cap and self.video_cap.isOpened():\n",
    "                    ret, frame = self.video_cap.read()\n",
    "                    if not ret:\n",
    "                        self.video_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                        continue\n",
    "                else:\n",
    "                    ret, frame = self.cap.read()\n",
    "                    if not ret:\n",
    "                        continue\n",
    "                \n",
    "                try:\n",
    "                    frame, its_value = self.process_frame(frame)\n",
    "                    self.its_label.config(text=f\"ITS: {its_value:.2f}\")\n",
    "                    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    image = Image.fromarray(image)\n",
    "                    image = ImageTk.PhotoImage(image)\n",
    "                    self.video_label.config(image=image)\n",
    "                    self.video_label.image = image\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error processing frame: {e}\")\n",
    "\n",
    "    \n",
    "    def start_video_thread(self):\n",
    "        if self.video_thread and self.video_thread.is_alive():\n",
    "            self.stop_video_thread.set()\n",
    "            self.video_thread.join()\n",
    "        self.stop_video_thread.clear()\n",
    "        self.video_thread = threading.Thread(target=self.update_video)\n",
    "        self.video_thread.daemon = True  # This ensures the thread stops when the main program exits\n",
    "        self.video_thread.start()\n",
    "\n",
    "    def close(self):\n",
    "        logger.info(\"Closing application...\")\n",
    "        self.stop_video_thread.set()\n",
    "        if self.video_thread and self.video_thread.is_alive():\n",
    "            self.video_thread.join()\n",
    "        if hasattr(self, 'cap') and self.cap.isOpened():\n",
    "            self.cap.release()\n",
    "        if self.video_cap and self.video_cap.isOpened():\n",
    "            self.video_cap.release()\n",
    "        if hasattr(self, 'video_writer'):\n",
    "            self.video_writer.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        self.window.destroy()\n",
    "        logger.info(\"Application closed successfully\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        logging.info(\"Starting Video Processing App\")\n",
    "        app = CameraApp()\n",
    "        app.run()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Application failed to start: {e}\")\n",
    "        messagebox.showerror(\"Error\", f\"Application failed to start: {e}\")\n",
    "    finally:\n",
    "        cv2.destroyAllWindows()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-09 12:19:53,619 - INFO - Starting Video Processing App\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
